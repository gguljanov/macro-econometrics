Maximum Likelihood estimation of \varp{} model is equivalent to OLS estimation under the assumption of normality for the error term. In the case of \varp[1]{} model, estimate of the transition matrix $\Phi_1$ is then:
\[
    \hat\Phi_1 = (X'X)^{-1} X'y
\]
where
\begin{align*}
    y & = \begin{bmatrix}
              y_{1, 1}   & y_{2, 1}   & \ldots & y_{N, 1}   \\
              y_{1, 2}   & y_{2, 2}   & \ldots & y_{N, 2}   \\
                         &            & \vdots &            \\
              y_{1, T-1} & y_{2, T-1} & \ldots & y_{N, T-1}
          \end{bmatrix}
    \\[0.8cm]
    X & = \begin{bmatrix}
              1 & y_{1, 2} & y_{2, 2} & \ldots & y_{N, 2} \\
              1 & y_{1, 3} & y_{2, 3} & \ldots & y_{N, 3} \\
                &          & \vdots   &                   \\
              1 & y_{1, T} & y_{2, T} & \ldots & y_{N, T}
          \end{bmatrix}.
\end{align*}

The covariance matrix of the error term is estimated using residuals, $\hat \nu_t$:
\[
    \hat V = \frac{1}{T-1} U' U
\]
with
\begin{align*}
    U & = \begin{bmatrix}
              \hat\nu_{1, 2} & \hat\nu_{2, 2} & \ldots & \hat\nu_{N, 2} \\
              \hat\nu_{1, 3} & \hat\nu_{2, 3} & \ldots & \hat\nu_{N, 3} \\
                             &                & \vdots &                \\
              \hat\nu_{1, T} & \hat\nu_{2, T} & \ldots & \hat\nu_{N, T}
          \end{bmatrix}
\end{align*}

\begin{enumerate}
    \item Simulate a dataset with $T=250$ using the following model, and estimate it with the approach described above:
          \begin{align*}
              \mu    & = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
              \\
              \Phi_1 & = \begin{bmatrix}
                             0.3 & 0.1 \\
                             0.2 & 0.4
                         \end{bmatrix}
              \\
              V      & = \begin{bmatrix}
                             0.23  & -0.10 \\
                             -0.10 & 0.32
                         \end{bmatrix}
          \end{align*}

          \begin{sol}
              \lstinputlisting{../R-files/monte_carlo_estimation_var1.R}
          \end{sol}

    \item Simulate $R = 100$ datasets, each with $T = 250$ observations with the model given in the subtask above. Estimate the elements of $\Phi_1$ with each data set and plot the histogram of the estimates. Do the same for $T = 2500, 25000$. Using the histogram, explain the consistency and asymptotic normality of MLE/OLS.

          \begin{sol}
              \lstinputlisting{../R-files/monte_carlo_estimation_var1.R}

              As can be seen from the results, as we have more data points our histograms become narrower horizontally. This means the variance decreases and thus shows the consistency.

              The histograms are bell-shaped curves around the true values. The bell-shape gets better and better as $T$ increases. This is asymptotic normality.
          \end{sol}
\end{enumerate}